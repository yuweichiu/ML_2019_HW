{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on 2019/9/29 下午 05:17\n",
    "@author: Ivan Y.W.Chiu\n",
    "\n",
    "python ./practice/cifar10_keras.py train --logs=./practice/logs\n",
    "python ./practice/cifar10_keras.py train --logs=./practice/logs --augmentation=1\n",
    "python ./practice/cifar10_keras.py train --logs=./practice/logs --augmentation=1 --resume=1 --weights=./practice/logs/D20190929T2220/cifar10_test_epoch020.h5\n",
    "python ./practice/cifar10_keras.py detect --logs=./practice/logs --weights=./practice/logs/D20191001T0153/cifar10_ResNet56v2_epoch003.h5\n",
    "\n",
    "\"\"\"\n",
    "import os, sys, time\n",
    "ROOT_PATH = r\"/media/yuwei/Data/YuWei/ML_DL/_Courses/HungYiLee/ML_2019_HW\"\n",
    "os.chdir(ROOT_PATH)\n",
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "# from practice.src import model as modellib\n",
    "import practice.src.model as modelib\n",
    "import practice.src.utils as utils\n",
    "from practice.src.config import Config\n",
    "import numpy as np\n",
    "\n",
    "DEFAULT_LOG_PATH = os.path.join(ROOT_PATH, \"hw3\", \"logs\")\n",
    "\n",
    "############################################################\n",
    "#  Session Setting\n",
    "############################################################\n",
    "# If you face the error about convolution layer,\n",
    "# use this block to enable the memory usage of GPU growth.\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "sess = tf.Session(config=tf_config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations:\n",
      "ACTIVATION_FUNC                relu\n",
      "BATCH_SIZE                     256\n",
      "BIAS_INIT_DEFAULT              0\n",
      "CONV2D_KERNEL_SIZE             (3, 3)\n",
      "CONV2D_PADDING                 SAME\n",
      "CONV2D_STRIDES                 1\n",
      "DROPOUT_RATE                   0\n",
      "EPOCHS                         3\n",
      "IMG_SHAPE                      [32, 32, 3]\n",
      "KERNEL_INIT_METHOD             glorot_normal\n",
      "LR                             0.001\n",
      "MAXPOOL2D_KERNEL_SIZE          (2, 2)\n",
      "MAXPOOL2D_PADDING              SAME\n",
      "MAXPOOL2D_STRIDES              2\n",
      "NAME                           cifar10_ResNet20v2\n",
      "N_CLASS                        10\n",
      "RESNET_DEPTH                   20\n",
      "SAVE_BEST_ONLY                 False\n",
      "SUBTRACT_PIXEL_MEAN            True\n",
      "UPSAMPLING_KERNEL_SIZE         2\n",
      "UPSAMPLING_METHOD              nearest\n",
      "VALIDATION_RATE                0\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "class Cifar10Config(Config):\n",
    "    # ResNetv2 depth (9n+2): \n",
    "    RESNET_DEPTH = 20\n",
    "\n",
    "    # The name of your work:\n",
    "    NAME = 'cifar10_ResNet{:s}v2'.format(str(RESNET_DEPTH))\n",
    "\n",
    "    # Number of class in dataset:\n",
    "    N_CLASS = 10\n",
    "\n",
    "    # The shape of image in dataset:\n",
    "    IMG_SHAPE = [32, 32, 3]\n",
    "\n",
    "    # Learning rate:\n",
    "    LR = 0.001\n",
    "\n",
    "    # Epochs:\n",
    "    EPOCHS = 3\n",
    "\n",
    "    # Training batch size:\n",
    "    BATCH_SIZE = 256\n",
    "\n",
    "    # Validation rate:\n",
    "    VALIDATION_RATE = 0\n",
    "\n",
    "config = Cifar10Config()\n",
    "config_list = config.display(print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yuwei/envs/cnn/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = modelib.NNModel(mode=\"training\", config=config, logdir=DEFAULT_LOG_PATH, resume=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  Datasets\n",
    "############################################################\n",
    "class Cifar10Dataset(utils.Dataset):\n",
    "    def feed_config(self, f_config):\n",
    "        self.config = f_config\n",
    "        self.n_class = f_config.N_CLASS\n",
    "        self.img_shape = f_config.IMG_SHAPE\n",
    "        self.val_rate = f_config.VALIDATION_RATE\n",
    "\n",
    "    def load(self, usage):\n",
    "        \"\"\"\n",
    "        Load the data (image, label) from dataset directory.\n",
    "        :param usage: 'train' or 'detect'\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if usage == 'train':\n",
    "            (self.x_data, self.y_data), _ = cifar10.load_data()\n",
    "        else:\n",
    "            _, (self.x_data, self.y_data) = cifar10.load_data()\n",
    "\n",
    "dataset = Cifar10Dataset()\n",
    "dataset.feed_config(config)\n",
    "dataset.load(usage='train')\n",
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.use_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 40000\n",
      "Validation set: 10000\n"
     ]
    }
   ],
   "source": [
    "dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
