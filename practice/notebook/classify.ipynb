{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "ROOT_PATH = r\"D:\\YuWei\\ML_DL\\_Courses\\HungYiLee\\ML_2019_HW\"\n",
    "os.chdir(ROOT_PATH)\n",
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "# from practice.src import model as modellib\n",
    "import practice.src.model as modelib\n",
    "import practice.src.utils as utils\n",
    "from practice.src.config import Config\n",
    "import practice.cifar10_keras as runfile\n",
    "import numpy as np\n",
    "\n",
    "DEFAULT_LOG_PATH = os.path.join(ROOT_PATH, \"logs\")\n",
    "\n",
    "############################################################\n",
    "#  Session Setting\n",
    "############################################################\n",
    "# If you face the error about convolution layer,\n",
    "# use this block to enable the memory usage of GPU growth.\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "sess = tf.Session(config=tf_config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations:\n",
      "ACTIVATION_FUNC                relu\n",
      "BATCH_SIZE                     1\n",
      "BIAS_INIT_DEFAULT              0\n",
      "CONV2D_KERNEL_SIZE             (3, 3)\n",
      "CONV2D_PADDING                 SAME\n",
      "CONV2D_STRIDES                 1\n",
      "DROPOUT_RATE                   0\n",
      "EPOCHS                         20\n",
      "IMG_SHAPE                      [32, 32, 3]\n",
      "KERNEL_INIT_METHOD             glorot_normal\n",
      "LR                             0.001\n",
      "MAXPOOL2D_KERNEL_SIZE          (2, 2)\n",
      "MAXPOOL2D_PADDING              SAME\n",
      "MAXPOOL2D_STRIDES              2\n",
      "NAME                           cifar10_test\n",
      "N_CLASS                        10\n",
      "SAVE_BEST_ONLY                 False\n",
      "UPSAMPLING_KERNEL_SIZE         2\n",
      "UPSAMPLING_METHOD              nearest\n",
      "VALIDATION_RATE                0.2\n"
     ]
    }
   ],
   "source": [
    "class Cifar10Config(Config):\n",
    "    # The name of your work:\n",
    "    NAME = 'cifar10_test'\n",
    "\n",
    "    # Number of class in dataset:\n",
    "    N_CLASS = 10\n",
    "\n",
    "    # The shape of image in dataset:\n",
    "    IMG_SHAPE = [32, 32, 3]\n",
    "\n",
    "    # Learning rate:\n",
    "    LR = 0.001\n",
    "\n",
    "    # Epochs:\n",
    "    EPOCHS = 20\n",
    "\n",
    "    # Training batch size:\n",
    "    BATCH_SIZE = 256\n",
    "\n",
    "    # Validation rate:\n",
    "    VALIDATION_RATE = 0.2\n",
    "    \n",
    "class ClassifyConfig(Cifar10Config):\n",
    "    BATCH_SIZE = 1\n",
    "config = ClassifyConfig()\n",
    "config_list = config.display(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Configurations:',\n",
       " 'ACTIVATION_FUNC                relu',\n",
       " 'BATCH_SIZE                     1',\n",
       " 'BIAS_INIT_DEFAULT              0',\n",
       " 'CONV2D_KERNEL_SIZE             (3, 3)',\n",
       " 'CONV2D_PADDING                 SAME',\n",
       " 'CONV2D_STRIDES                 1',\n",
       " 'DROPOUT_RATE                   0',\n",
       " 'EPOCHS                         20',\n",
       " 'IMG_SHAPE                      [32, 32, 3]',\n",
       " 'KERNEL_INIT_METHOD             glorot_normal',\n",
       " 'LR                             0.001',\n",
       " 'MAXPOOL2D_KERNEL_SIZE          (2, 2)',\n",
       " 'MAXPOOL2D_PADDING              SAME',\n",
       " 'MAXPOOL2D_STRIDES              2',\n",
       " 'NAME                           cifar10_test',\n",
       " 'N_CLASS                        10',\n",
       " 'SAVE_BEST_ONLY                 False',\n",
       " 'UPSAMPLING_KERNEL_SIZE         2',\n",
       " 'UPSAMPLING_METHOD              nearest',\n",
       " 'VALIDATION_RATE                0.2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\envs\\cnn\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Name                      | Input_shape               | Kernel size          | Strides  | Padding  | Output_shape        \n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "conv2d_1                  | (None, 32, 32, 3)         | (5, 5, 3, 64)        | (1, 1)   | same     | (None, 32, 32, 64)  \n",
      "batch_normalization_1     | (None, 32, 32, 64)        |                      |          |          |                     \n",
      "activation_1/Relu:0       |                           |                      |          |          |                     \n",
      "max_pooling2d_1           | (None, 32, 32, 64)        | (2, 2)               | (2, 2)   | same     | (None, 16, 16, 64)  \n",
      "conv2d_2                  | (None, 16, 16, 64)        | (5, 5, 64, 128)      | (1, 1)   | same     | (None, 16, 16, 128) \n",
      "batch_normalization_2     | (None, 16, 16, 128)       |                      |          |          |                     \n",
      "activation_2/Relu:0       |                           |                      |          |          |                     \n",
      "max_pooling2d_2           | (None, 16, 16, 128)       | (2, 2)               | (2, 2)   | same     | (None, 8, 8, 128)   \n",
      "conv2d_3                  | (None, 8, 8, 128)         | (5, 5, 128, 256)     | (1, 1)   | same     | (None, 8, 8, 256)   \n",
      "batch_normalization_3     | (None, 8, 8, 256)         |                      |          |          |                     \n",
      "activation_3/Relu:0       |                           |                      |          |          |                     \n",
      "max_pooling2d_3           | (None, 8, 8, 256)         | (2, 2)               | (2, 2)   | same     | (None, 4, 4, 256)   \n",
      "flatten_1                 | (None, 4, 4, 256)         |                      |          |          | (None, 4096)        \n",
      "dense_1                   | (None, 4096)              | 512                  |          |          | (None, 512)         \n",
      "batch_normalization_4     | (None, 512)               |                      |          |          |                     \n",
      "activation_4/Relu:0       |                           |                      |          |          |                     \n",
      "dropout_1                 | 0.0                       |                      |          |          |                     \n",
      "dense_2                   | (None, 512)               | 10                   |          |          | (None, 10)          \n",
      "activation_5/Softmax:0    |                           |                      |          |          |                     \n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "WARNING:tensorflow:From c:\\envs\\cnn\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Load weights cifar10_test_epoch020.h5 from ./practice/logs/D20190930T0035/\n"
     ]
    }
   ],
   "source": [
    "weights_path = \"./practice/logs/D20190930T0035/cifar10_test_epoch020.h5\"\n",
    "model = modelib.NNModel(mode=\"classify\", config=config, logdir=None, resume=0)\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10Dataset(utils.Dataset):\n",
    "    def feed_config(self, config):\n",
    "        self.n_class = config.N_CLASS\n",
    "        self.img_shape = config.IMG_SHAPE\n",
    "        self.val_rate = config.VALIDATION_RATE\n",
    "\n",
    "    def load(self, usage):\n",
    "        if usage == 'train':\n",
    "            (self.x_data, self.y_data), _ = cifar10.load_data()\n",
    "            total = self.x_data.shape[0]\n",
    "            self.x_data = self.x_data[0: int(total * (1 - self.val_rate))]\n",
    "            self.y_data = self.y_data[0: int(total * (1 - self.val_rate))]\n",
    "        elif usage == 'val':\n",
    "            (self.x_data, self.y_data), _ = cifar10.load_data()\n",
    "            total = self.x_data.shape[0]\n",
    "            self.x_data = self.x_data[int(total * (1 - self.val_rate)): ]\n",
    "            self.y_data = self.y_data[int(total * (1 - self.val_rate)): ]\n",
    "        else:\n",
    "            _, (self.x_data, self.y_data) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = Cifar10Dataset()\n",
    "dataset_test.feed_config(config)\n",
    "dataset_test.load('test')\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 272us/step\n",
      "Saved prediction to ./practice/logs/D20190930T0035/classify_cifar10_test_epoch020.csv\n"
     ]
    }
   ],
   "source": [
    "prediction = model.classify(dataset_test.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7738\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(prediction['label'].values, np.argmax(dataset_test.y_data, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
